# What is Big O Notation?

Big O notation is a mathematical concept used in computer science to describe the performance or complexity of an algorithm. It helps us understand how an algorithm's runtime or space requirements grow as the input size increases.

## How important of Big O Notation?
Big O notation is important and crucial for understanding the efficiency of algorithms, especially as the size of the input data grows. It helps in determining the **time complexity** (how long an algorithm takes to run) and **space complexity** (how much memory it uses)